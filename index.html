<!DOCTYPE html>
<!-- saved from url=(0028)https://rajpurkar.github.io/ -->
<html class="gr__rajpurkar_github_io">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Wahab Hussain</title>
    <meta name="description" content="Wahab Hussain.">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <meta property="og:image" content="/images/me.jpg">
    <link rel="image_src" type="image/jpeg" href="https://hellowahab.github.io/images/me.jpg">
    <link rel="shortcut icon" href="https://hellowahab.github.io/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://hellowahab.github.io/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="./index_files/bootstrap.min.css">
    <link rel="stylesheet" href="./index_files/font-awesome.min.css">
    <link rel="stylesheet" href="./index_files/layout.css">
    <script async="" src="./index_files/analytics.js.download"></script>
    <link rel="stylesheet" href="./index_files/index.css">
</head>
<body data-gr-c-s-loaded="true">
    <div id="StayFocusd-infobar" style="display: none; top: 0px;">
        <img src="chrome-extension://laankejkbhbdhmipfmgcngdelahlfoji/common/img/eye_19x19_red.png">
        <span id="StayFocusd-infobar-msg"></span>
        <span id="StayFocusd-infobar-links">
            <a id="StayFocusd-infobar-never-show">hide forever</a>&nbsp;&nbsp;|&nbsp;&nbsp;
            <a id="StayFocusd-infobar-hide">hide once</a>
        </span>
    </div>
    <div class="outer">
        <div class="sidebar">
            <div class="cover" id="leftCover">
                <div class="vertical-center">
                    <div class="container">
                        <div class="row">
                            <img class="media-object img-circle" id="me" src="./index_files/wahabhussain.jpg">
                            <h1>Wahab Hussain</h1>
                            <h3>
                                Sofware Development Lead
                                <br> Creative Chaos
                            </h3>
                            <h4>hellowahab@gmail.com</h4>
                            <ul class="list-inline outside-links">
                                <li>
                                    <a href="https://github.com/hellowahab"><i class="fa fa-github"></i></a>
                                </li>
                                <li>
                                    <a href="https://twitter.com/hellowahab"><i class="fa fa-twitter"></i></a>
                                </li>
                                <li>
                                    <a href="http://linkedin/in/hellowahab"><i class="fa fa-linkedin"></i></a>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div class="contentbar">
            <div class="cover" id="rightCover">
                <div class="col-lg-8 col-lg-offset-1 col-md-9 col-md-offset-1 col-sm-10 col-sm-offset-1">
                    <h1>About</h1>
                    <p>
                        Wahab Hussain is focused toward Payment Processing Systems and also leading a Software Development team for Boloro (A Mobile Payment Gateway). He is actively involved in requirement gathering, project management and software development activities (.Net). He is an active contributor toward the architectural improvements, both at application and network infrastructure level. He is an active researcher on hardware usage within payment systems and kiosks. His focus is toward the efficient utilization of Software, Hardware, and Network to achieve maximum transactions per second (tps). He has been actively involved in customized fraud preventing and analytical rule engines. He has actively participated in ISO-8583 implementation, EMV research and NFC-based readers and tags implementations. His expertise involves SOAP, Rest based services as well as SMPP and USSD implementations. He is actively involved in several components to facilitate the business expansion within a payment gateway.

                        Apart from his focus on Payment Processing Systems, he has been working in software development field since 2005. He has worked on diverse nature of projects ranging from desktop based business solution to web based solution. He has worked on an in-house developed ERP consisting of different modules like Sales, Purchase, Inventory, GL etc. He has also worked on a web-based custom CRM. He has worked on a Web-based Fund Management System using Php Zend Framework. He has worked on school management system and customized MIS Systems for different clients. Apart from these listed projects he stay engaged in several other technical endeavors.

                        At software community level, he has contributed several articles on Code Project. Posted answers on Asp.net Forums, Stack Overflow, participated in MVA and Coursera course. He also shares his knowledge by writing a blog at hellowahab.wordpress.com
                    </p>
                    <!--<div class="project">
                        <h2>ChexNet - Radiologist-Level Pneumonia Detection </h2>
                        <h3>Active project for 3 months with Jeremy Irvin and Professor Matt Lungren, Professor Andrew Ng</h3>
                        <p>We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists. Our model, CheXNet, is a 121-layer convolutional neural network that inputs a chest X-ray image and outputs the probability of pneumonia along with a heatmap localizing the areas of the image most indicative of pneumonia. We train on ChestX-ray14, the largest publicly available chest X-ray dataset. We find that the model exceeds the average radiologist performance at the pneumonia detection task on both sensitivity and specificity.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://stanfordmlgroup.github.io/projects/chexnet">Project Webpage</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://arxiv.org/abs/1711.05225">Paper (Arxiv)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://news.stanford.edu/2017/11/15/algorithm-outperforms-radiologists-diagnosing-pneumonia/">Press (Stanford News)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://spectrum.ieee.org/the-human-os/biomedical/diagnostics/stanford-algorithm-can-diagnose-pneumonia-better-than-radiologists">Press (IEEE Spectrum)</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>Cardiologist-Level Arrhythmia Detection </h2>
                        <h3>Active project for a year with Awni Hannun and Professor Andrew Ng</h3>
                        <p>Our deep learning algorithm exceeds the performance of board certified cardiologists in detecting a wide range of heart arrhythmias from electrocardiograms recorded with a single-lead wearable monitor. Dataset 500x larger than previously studied corpora used to train a deep convolutional neural network.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://stanfordmlgroup.github.io/projects/ecg">Project Webpage</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://arxiv.org/abs/1707.01836">Paper (Arxiv)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://news.stanford.edu/2017/07/06/algorithm-diagnoses-heart-arrhythmias-cardiologist-level-accuracy/">Press (Stanford News)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://www.technologyreview.com/s/608234/the-machines-are-getting-ready-to-play-doctor/">Press (MIT Technology Review)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://www.youtube.com/watch?v=XVDDEsmbjuE">Video (Stanford)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://www.youtube.com/watch?v=_sh8FkKmKI8">Podcast (Data Skeptic)</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>SQuAD </h2>
                        <h3>Active project for 2 years with Professor Percy Liang</h3>
                        <p>Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage. With 107,785 question-answer pairs on 536 articles, SQuAD is significantly larger than previous reading comprehension datasets.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://stanford-qa.com/">SQuAD</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://arxiv.org/abs/1606.05250">Paper (EMNLP 2016) (Best Resource Paper)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://rajpurkar.github.io/mlx/qa-and-squad/">Blogpost</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>Edusalsa </h2>
                        <h3>Active project for 4 years with Brad Girardeau</h3>
                        <p>A single class can transform a life. A popular introduction to programming class leads to the discovery of a passion for computer science, a social dance class exposes a deep appreciation for artistic expression--experiences like these are at the core of a Stanford education. Yet out of the 5000 classes offered here, students only have time to take less than 1% during their undergraduate career. This small selection of classes determines the foundation on which passions are developed - passions that lead to great innovations and great discoveries that change the world. Some students arrive at Stanford with clear visions of their futures. Others need a little time to explore and decide what to do with their lives. Edusalsa lets students find the classes where they can discover their passions, equipping them with new tools on their path of intellectual discovery, infusing life and vitality into the Stanford experience.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://edusalsa.com/">Edusalsa</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://www.stanforddaily.com/tag/edusalsa/">Press (Stanford Daily)</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>Driverseat </h2>
                        <h3>From Jan 2013 up to May 2015 with Professor Andrew Ng</h3>
                        <p>Research in Autonomous Driving spanning Computer Vision, Artificial Intelligence, and Crowdsourcing. My undergraduate honors research introduced Driverseat, a technology for embedding crowds around learning systems for autonomous driving.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://arxiv.org/abs/1512.01872">Paper 1 (CrowdML@ICML'15)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://www.technologyreview.com/s/544926/ai-machine-learns-to-drive-using-crowdteaching/">Press (MIT Technology Review)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://www.youtube.com/watch?v=7b3XEBVGQHs">Driverseat video demo</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://arxiv.org/abs/1504.01716">Paper 2 (Arxiv)</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>Recommend Papers </h2>
                        <h3>From Jul 2015 up to Dec 2015 with Professor Andrew Ng, Professor Yoshua Bengio et al.</h3>
                        <p>Piloted for the Deep Learning Symposium at NIPS '15, Recommend-Papers was built in order to facilitate discussion of the most recent deep learning breakthroughs and explore an alternative mechanism for selecting presentations. In order to let the broader research community (including the authors of research papers) contribute to the discussion, Recommend-Papers allowed members to post papers and comment on them, and PC members to hold private discussions.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://recommend-papers.herokuapp.com/">Recommend-Papers</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>Chord Recognition </h2>
                        <h3>From Oct 2014 up to Dec 2014 with Brad Girardeau and Toki Migimatsu</h3>
                        <p>Can a computer identify the chord I'm playing on a guitar simply by  listening to it? How well does machine learning perform on the task realtime? Could we leverage that technology to give realtime feedback to an instrument learner? This research presents a prototype of an online tool for real-time chord recognition. It fuses traditional techniques in machine learning with the capabilities of new web technologies such the the Web Audio API, and WebSockets.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://rajpurkar.github.io/files/GirardeauMigimatsuRajpurkar-ASupervisedApproachToChordRecognitionFinal.pdf">Paper (SURJ '15)</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>MLX </h2>
                        <h3>Active project for a year</h3>
                        <p>Machine Learning Experiments (mlx) is a blog to showcase machine learning work intended to showcase machine learning experiments not just in their final polished form, but also highlight the thought process that guides research.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://rajpurkar.github.io/mlx/">MLX Blog</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>Augur </h2>
                        <h3>From Jun 2014 up to Sep 2014 with Ethan Fast and Professor Michael Bernstein</h3>
                        <p>Research in Human Computer Interaction, and Natural Language Processing, exploring how we could teach a computer enough about human actions to enable predictive application interfaces that could, for example, recommend ice cream shops upon learning that a person was having dinner.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://arxiv.org/abs/1602.06977">Paper (CHI 2016) (Best Paper Honorable Mention)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://www.theglobeandmail.com/technology/tech-news/stanford-researchers-using-wattpad-stories-to-inform-artificial-intelligence/article29042748/">Press (The Globe and Mail)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://www.engadget.com/2016/02/28/ai-learns-to-predict-human-reactions-by-reading-our-fiction/">Press (Engadget)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="https://thestack.com/cloud/2016/02/26/computers-read-1-8-billion-words-of-fiction-to-learn-how-to-anticipate-human-behaviour/">Press (The Stack)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://www.teleread.com/can-books-teach-machines-to-understand-people/">Press (Teleread)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://www.hngn.com/articles/183248/20160229/trained-understand-predict-human-behavior-reading-books.htm">Press (HNGN)</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://dl.acm.org/citation.cfm?id=2732805">Paper (CHI EA '15)</a>
                            </li>
                        </ul>
                    </div>
                    <div class="project">
                        <h2>Vocalet </h2>
                        <h3>From Jan 2013 up to Mar 2013 with Vincent Su</h3>
                        <p>Singing is awesome, powerful, and personal. Can we simplify, for amateur singers, the process of exploring new songs to sing along to? Vocalet provides a simple interface for singing enthusiasts to enjoy. It's easy to sing along to karaoke versions of songs, and get inspired by cover artists.</p>
                        <ul class="list-inline">
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://vocalet.com/">Vocalet</a>
                            </li>
                            <li>
                                <a class="btn actionBtn inverseBtn" href="http://www.youtube.com/embed/LPoLC1uTH9w">Showcase Video</a>
                            </li>
                        </ul>
                    </div>-->
                    <p></p>
                </div>
            </div>
        </div>
    </div>
    <script src="./index_files/jquery.min.js.download"></script>
    <script src="./index_files/bootstrap.min.js.download"></script>
    <div id="shadowMeasureIt"></div>
    <div id="divCoordMeasureIt"></div>
    <div id="divRectangleMeasureIt">
        <div id="divRectangleBGMeasureIt"></div>
    </div>
</body>
<span class="gr__tooltip"><span class="gr__tooltip-content"></span><i class="gr__tooltip-logo"></i><span class="gr__triangle"></span></span>
</html>
